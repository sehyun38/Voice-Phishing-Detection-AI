import torch
import tkinter as tk
from transformers import AutoTokenizer
from my_models import BiLSTMAttention, TextCNN, RCNN, KLUEBertModel

# === ì„¤ì • ===
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
USE_BERT_MODEL = True  # True ì‹œ BERT ëª¨ë¸ í¬í•¨

EMBEDDING_DIM = 256
HIDDEN_DIM = 128
NUM_CLASSES = 2

# BERT tokenizer ê¸°ë°˜ vocab size
tokenizer = AutoTokenizer.from_pretrained("klue/bert-base", trust_remote_code=True)
VOCAB_SIZE = len(tokenizer)

# === ëª¨ë¸ ì„¤ì • ===
MODEL_CONFIGS = {
    "bilstm": {
        "class": BiLSTMAttention,
        "weight_path": "../Result/BiLSTM/model/best_model.pth",
        "init_args": {
            "vocab_size": VOCAB_SIZE,
            "embed_dim": EMBEDDING_DIM,
            "hidden_dim": HIDDEN_DIM,
            "num_classes": NUM_CLASSES
        }
    },
    "textcnn": {
        "class": TextCNN,
        "weight_path": "../Result/TextCNN/model/best_model.pth",
        "init_args": {
            "vocab_size": VOCAB_SIZE,
            "embed_dim": EMBEDDING_DIM,
            "num_classes": NUM_CLASSES
        }
    },
    "rcnn": {
        "class": RCNN,
        "weight_path": "../Result/RCNN/model/best_model.pth",
        "init_args": {
            "vocab_size": VOCAB_SIZE,
            "embed_dim": EMBEDDING_DIM,
            "hidden_dim": HIDDEN_DIM,
            "num_classes": NUM_CLASSES
        }
    },
    "bert": {
        "class": KLUEBertModel,
        "weight_path": "../Result/kluebert_v1/model/best_model.pth",
        "init_args": {
            "bert_model_name": "klue/bert-base",
            "num_classes": NUM_CLASSES
        }
    }
}


# ëª¨ë¸ ë¡œë”© í•¨ìˆ˜
def load_model(model_class, weight_path, init_args):
    model = model_class(**init_args).to(DEVICE)
    state_dict = torch.load(weight_path, map_location=DEVICE)
    model.load_state_dict(state_dict)
    model.eval()
    return model


# ëª¨ë¸ ëª©ë¡
model_keys = ["bilstm", "textcnn", "rcnn"]
if USE_BERT_MODEL:
    model_keys.append("bert")

models = [
    load_model(
        MODEL_CONFIGS[key]["class"],
        MODEL_CONFIGS[key]["weight_path"],
        MODEL_CONFIGS[key]["init_args"]
    )
    for key in model_keys
]


# === ì˜ˆì¸¡ í•¨ìˆ˜ ===
def encode_text(tokenizer, text):
    """ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ input_idsì™€ attention_maskë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜ """
    encoded = tokenizer(
        text,
        padding="max_length",  # ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©
        truncation=True,  # ìë¥´ê¸°
        max_length=360,  # 360ìœ¼ë¡œ íŒ¨ë”© ìµœëŒ€ ê¸¸ì´ ì„¤ì •
        return_tensors="pt"
    )
    return encoded["input_ids"].to(DEVICE), encoded["attention_mask"].to(DEVICE)


def predict_model(model, input_ids, attention_mask=None):
    """ ëª¨ë¸ì— ëŒ€í•œ ì˜ˆì¸¡ í•¨ìˆ˜ """
    with torch.no_grad():
        # ëª¨ë¸ì´ attention_maskë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ ì²´í¬í•˜ê³  í•´ë‹¹ ì…ë ¥ì„ ì „ë‹¬
        if "attention_mask" in model.forward.__code__.co_varnames:
            logits = model(input_ids=input_ids, attention_mask=attention_mask)
        else:
            logits = model(input_ids)
        probs = torch.softmax(logits, dim=-1).squeeze().cpu().numpy().tolist()
        return probs  # [p0, p1]


def predict_soft_voting(text, threshold=0.6):
    """ Soft Voting ë°©ì‹ ì˜ˆì¸¡ """
    # í…ìŠ¤íŠ¸ë¡œë¶€í„° input_idsì™€ attention_mask ìƒì„±
    input_ids, attention_mask = encode_text(tokenizer, text)

    # ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°
    all_probs = [predict_model(model, input_ids, attention_mask) for model in models]  # [[p0, p1], ...]

    # í™•ë¥ ì˜ í‰ê· ì„ êµ¬í•¨
    avg_probs = torch.tensor(all_probs).mean(dim=0).tolist()  # í‰ê·  í™•ë¥  [p0, p1]

    # threshold ì ìš© (class 1 í™•ë¥ ì´ threshold ì´ìƒì´ë©´ 1, ì•„ë‹ˆë©´ 0)
    prediction = int(avg_probs[1] >= threshold)  # class 1 í™•ë¥  ê¸°ì¤€ íŒë‹¨
    confidence = avg_probs[1]

    return prediction, confidence, avg_probs


# === GUI ì•± ===
class VoicePhishingApp:
    def __init__(self, root, tokenizer):
        self.tokenizer = tokenizer
        self.root = root
        self.root.title("ë³´ì´ìŠ¤í”¼ì‹± íƒì§€ê¸° (Ensemble Stacking)")
        self.root.geometry("500x400")
        self.log_enabled = False
        self.debounce_after_id = None
        self.build_ui()

    def build_ui(self):
        tk.Label(self.root, text="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", font=("Arial", 12)).pack(pady=10)

        self.text_input = tk.Text(self.root, height=6, width=45, wrap='word', font=("Arial", 12))
        self.text_input.pack(pady=15)

        self.result_label = tk.Label(self.root, text="ì…ë ¥ëœ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.", font=("Arial", 12))
        self.result_label.pack(pady=10)

        # ë¡œê·¸ ì¶œë ¥ í† ê¸€
        self.log_toggle_button = tk.Button(self.root, text="í„°ë¯¸ë„ ì¶œë ¥ OFF", bg='gray', font=("Arial", 10, "bold"))
        self.log_toggle_button.config(command=self.toggle_log_output)
        self.log_toggle_button.pack(pady=5)

        self.text_input.bind('<KeyRelease>', self.debounced_prediction)

    def toggle_log_output(self):
        self.log_enabled = not self.log_enabled
        if self.log_enabled:
            self.log_toggle_button.config(text="í„°ë¯¸ë„ ì¶œë ¥ ON", bg='green')
        else:
            self.log_toggle_button.config(text="í„°ë¯¸ë„ ì¶œë ¥ OFF", bg='gray')

    def debounced_prediction(self, event, delay=300):
        if self.debounce_after_id is not None:
            self.root.after_cancel(self.debounce_after_id)
        self.debounce_after_id = self.root.after(delay, self.perform_prediction)

    def perform_prediction(self):
        text = self.text_input.get("1.0", "end").strip()
        if not text:
            self.result_label.config(text="í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", fg="gray")
            return

        try:
            label, score, avg_probs = predict_soft_voting(text)  # ì—¬ê¸°ì„œ í…ìŠ¤íŠ¸ë¡œ ì§ì ‘ ì˜ˆì¸¡ ìˆ˜í–‰
            result_text = f"{'ë³´ì´ìŠ¤í”¼ì‹± ì˜ì‹¬' if label == 1 else 'ğŸŸ¢ ì •ìƒ'} (í™•ë¥ : {score * 100:.2f}%)"
            result_color = 'red' if label == 1 else 'green'
            self.result_label.config(text=result_text, fg=result_color)

            if self.log_enabled:
                print("ì…ë ¥ëœ í…ìŠ¤íŠ¸:", text)
                print("ì˜ˆì¸¡ ê²°ê³¼:", "ë³´ì´ìŠ¤í”¼ì‹± ì˜ì‹¬" if label == 1 else "ì •ìƒ")
                print("í™•ë¥ :", f"{score * 100:.2f}%")
                print("-" * 40)

        except Exception as e:
            self.result_label.config(text=f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", fg="orange")
            if self.log_enabled:
                print("[ì˜¤ë¥˜]", str(e))


# === ë©”ì¸ ===
def main():
    tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")
    root = tk.Tk()
    app = VoicePhishingApp(root, tokenizer)
    root.mainloop()


if __name__ == "__main__":
    main()
